---
title: Logistic回归的R实现
author: "Yu Nongxin"
date: 2017-11-03
slug: logistic-regression-in-r
categories: ["Machine Learning"]
tags: ["R","Logistic Regression"]
---



<p>在统计学习和机器学习中，logistic回归是应用最广泛的一种分类方法，其模型通常针对二分类问题，并且具有较好的解释能力。logistic回归模型可以有条件概率分布<span class="math inline">\(P(Y|X)\)</span>表示，此时随机变量<span class="math inline">\(X\)</span>取值为实数，随机变量<span class="math inline">\(Y\)</span>取值为1或0.我们可以通过监督学校的方法来估计模型参数。</p>
<p><em>定义</em> <span class="math display">\[
P(Y=1|x)=\frac{exp(\omega *x+b)}{1+exp(\omega *x+b)}
\]</span> <span class="math display">\[
P(Y=0|x)=\frac{1}{1+exp(\omega *x+b)}
\]</span> 对于给定的输入实例<span class="math inline">\(x\)</span>，按照上式可以求出<span class="math inline">\(P(Y=1|x)\)</span>和<span class="math inline">\(P(Y=0|x)\)</span>。logistic回归将比较两个条件概率值得大小，将实例<span class="math inline">\(x\)</span>分到概率值较大的那一类。</p>
<p>一个事件的几率（odds）是指该事件发生的概率与该事件不发生的概率的比值，如果事件发生的概率是p，那么该事件的几率是<span class="math inline">\(\frac{p}{1-p}\)</span>，该事件的对数几率（log odds）或logit函数是 <span class="math display">\[
logit(p)=log\frac{p}{1-p}
\]</span> 对logistic回归而言，即有： <span class="math display">\[
log\frac{P(Y=1|x)}{1-P(Y=1|x)}=\omega \cdot x
\]</span> 这就是说，在logistic回归模型中，输出<span class="math inline">\(Y=1\)</span>的对数几率是输入<span class="math inline">\(x\)</span>的线性函数。因此我们也把logistic回归归为广义线性模型（GLM）的一种。</p>
<p>下面我们用Titanic数据集在R中演示logistic回归模型。</p>
<p>首先读入Titanic数据集</p>
<pre class="r"><code>Titanic &lt;- read.table(&#39;C:/Users/Lovely/Documents/R/titanic.txt&#39;)</code></pre>
<p>然后我们先看一下数据集的构成</p>
<pre class="r"><code>str(Titanic)</code></pre>
<pre><code>## &#39;data.frame&#39;:    2201 obs. of  4 variables:
##  $ V1: int  1 1 1 1 1 1 1 1 1 1 ...
##  $ V2: int  1 1 1 1 1 1 1 1 1 1 ...
##  $ V3: int  1 1 1 1 1 1 1 1 1 1 ...
##  $ V4: int  1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<pre class="r"><code>summary(Titanic)</code></pre>
<pre><code>##        V1              V2               V3               V4       
##  Min.   :0.000   Min.   :0.0000   Min.   :0.0000   Min.   :0.000  
##  1st Qu.:0.000   1st Qu.:1.0000   1st Qu.:1.0000   1st Qu.:0.000  
##  Median :1.000   Median :1.0000   Median :1.0000   Median :0.000  
##  Mean   :1.369   Mean   :0.9505   Mean   :0.7865   Mean   :0.323  
##  3rd Qu.:3.000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.000  
##  Max.   :3.000   Max.   :1.0000   Max.   :1.0000   Max.   :1.000</code></pre>
<p>根据数据源对应的介绍，四个变量分别是Class，Sex，Age，Survived。我们给原始数据添加对应名称。</p>
<pre class="r"><code>Titanic &lt;- `colnames&lt;-`(Titanic,c(&#39;Class&#39;,&#39;Sex&#39;,&#39;Age&#39;,&#39;Survived&#39;))</code></pre>
<p>然后我们使用<code>glm()</code>函数建立logistic回归模型</p>
<pre class="r"><code>fit &lt;- glm(Survived~.,data = Titanic, family = binomial(link = &#39;logit&#39;))
summary(fit)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Survived ~ ., family = binomial(link = &quot;logit&quot;), 
##     data = Titanic)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.8989  -0.7879  -0.5877   0.7022   2.0615  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  2.60985    0.29360   8.889  &lt; 2e-16 ***
## Class       -0.32904    0.04648  -7.079 1.45e-12 ***
## Sex         -1.00627    0.24565  -4.096 4.20e-05 ***
## Age         -2.61420    0.13329 -19.613  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2769.5  on 2200  degrees of freedom
## Residual deviance: 2274.9  on 2197  degrees of freedom
## AIC: 2282.9
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre class="r"><code>summary(fit$fitted.values)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.1194  0.1586  0.2669  0.3230  0.2669  0.9073</code></pre>
<p>此时我们可以看到模型的各个参数都显著，因此我们认为模型拟合的是很好的，而根据对拟合值分布的观察情况可以看出其都是分布在<span class="math inline">\([0,1]\)</span>之间的。我们在通过判断概率值大小来比较模型分类的正确率。</p>
<pre class="r"><code>fit_value &lt;- fit$fitted.values
library(dplyr)
fit_value &lt;- if_else(fit_value &lt; 0.5, 0 , 1)
table(fit_value,Titanic$Survived)</code></pre>
<pre><code>##          
## fit_value    0    1
##         0 1364  367
##         1  126  344</code></pre>
<p>可以看出模型分类的准确率在77.6%，整体表现还行，但是通过一些其他方法还能够进一步提升模型的准确率。</p>
